{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Maximum Entropy Principle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "+ Demonstrate the maximum entropy principle through some examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Entropy of 2-state Distribution\n",
    "\n",
    "Consdider a distribution with two states, say $0$ and $1$.\n",
    "If the probability of $0$ is $p$, then the entropy of the distribution is:\n",
    "$$\n",
    "H_2(p, 1-p) = -p\\log p - (1-p)\\log (1-p)\n",
    "$$\n",
    "Let's plot this with respect to p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "p = np.linspace(0, 1, 100)\n",
    "H = -p * np.log(p) - (1. - p) * np.log(1. - p)\n",
    "ax.plot(p, H)\n",
    "ax.set_xlabel('$p$')\n",
    "ax.set_ylabel('$H_2(p, 1-p)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The Brandeis Dice Problem\n",
    "This is from the 1962 Brandeis lectures of E. T. Jaynes.\n",
    "\n",
    "> When a die is tossed, the number of spots up can have any value $i$ in $1\\le i \\le 6$. Suppose a die has been tossed $N$ times and we are told only that the average number of spots up was not $3.5$ as we might expect from an \"honest\" but 4.5. Given this information, <u>and nothing else</u>, what probability should we assign to $i$ spots on the next toss?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data impose the following mean value constraint:\n",
    "$$\n",
    "\\sum_{i=1}^6 i p_i = 4.5.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The partition function is:\n",
    "$$\n",
    "Z(\\lambda) = \\sum_{i}e^{-\\lambda i} = e^{-\\lambda} + e^{-2\\lambda} + \\dots + e^{-6\\lambda},\n",
    "$$\n",
    "or\n",
    "$$\n",
    "Z(\\lambda) = \\left(e^{-\\lambda}\\right)^1+\\left(e^{-\\lambda}\\right)^2 + \\dots + \\left(e^{-\\lambda}\\right)^6,\n",
    "$$\n",
    "which is equal to:\n",
    "$$\n",
    "Z(\\lambda) = \\frac{e^{-\\lambda}\\left(1-e^{-6\\lambda}\\right)}{1 - e^{-\\lambda}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find $\\lambda$, we must solve:\n",
    "$$\n",
    "-\\frac{\\partial Z}{\\partial \\lambda} = 4.5.\n",
    "$$\n",
    "This becomes:\n",
    "$$\n",
    "\\frac{1 - 7e^{-6\\lambda} + 6e^{7\\lambda}}{(1 - e^{-\\lambda})(1 - e^{-6\\lambda})} = 4.5,\n",
    "$$\n",
    "or\n",
    "$$\n",
    "3\\left(e^{-\\lambda}\\right)^7 - 5 \\left(e^{-\\lambda}\\right)^6 + 9e^{-\\lambda} - 7 = 0.\n",
    "$$\n",
    "Let's solve this numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import brentq\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# x = exp(-lambda)\n",
    "def f(x):\n",
    "    return 3. * x ** 7 - 5 * x ** 6 + 9. * x - 7.\n",
    "\n",
    "# Left bound for x\n",
    "a = 0.\n",
    "# Right bound for x\n",
    "b = 10.\n",
    "x = brentq(f, a, b)\n",
    "lam = -math.log(x)\n",
    "print 'Lambda:', lam\n",
    "# Evaluate the partition function at this lambda\n",
    "Z = math.exp(-lam) * (1. - math.exp(-6 * lam)) / (1. - math.exp(-lam))\n",
    "print 'Z:', Z\n",
    "# The log of Z\n",
    "log_Z = math.log(Z)\n",
    "print 'log Z:', log_Z\n",
    "# The maximum entropy probabilities\n",
    "p = np.exp(-lam * np.arange(1, 7)) / Z\n",
    "print 'p: ', p \n",
    "# The entropty of this distribution is:\n",
    "S = log_Z + lam * 4.5\n",
    "print 'S:', S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's plot this:\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.bar(np.arange(1, 7), p, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "+ Repeat the analysis for a mean of 3.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Repeat the analysis for a mean of $1.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Repeat assuming that we now know that the second moment is 2.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
